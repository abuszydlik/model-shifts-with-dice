{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f608fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Passing\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Implicit\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24d0e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla.models.catalog.load_model as loading_utils\n",
    "import carla.models.catalog.train_model as training_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from carla import log\n",
    "from carla import MLModelCatalog\n",
    "from carla.data.catalog import DataCatalog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca8213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicCsvCatalog(DataCatalog):\n",
    "    \"\"\"\n",
    "    Wrapper class for the DataCatalog similar to the built-in CsvCatalog but with new capabilities\n",
    "    required to control data in the experiments.\n",
    "    \n",
    "    Attributes:\n",
    "        file_path (str): \n",
    "            Path to the .csv file containing the dataset.\n",
    "        categorical (List[str]): \n",
    "            Names of columns describing categorical features.\n",
    "        continuous (List[str]):\n",
    "            Names of columns describing continuous (i.e. numerical) features.\n",
    "        immutables (List[str]):\n",
    "            Names of columns describing immutable features, not supported by all generators.\n",
    "        target (str):\n",
    "            Name of the column that contains the target variable.\n",
    "        test_size (float):\n",
    "            Proportion of the dataset which should be withheld as an independent test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_path: str, categorical: List[str],  continuous: List[str],\n",
    "                 immutables: List[str], target: str, test_size: float,\n",
    "                 scaling_method: str = \"MinMax\", encoding_method: str = \"OneHot_drop_binary\"):\n",
    "        \n",
    "        self._categorical = categorical\n",
    "        self._continuous = continuous\n",
    "        self._immutables = immutables\n",
    "        self._target = target\n",
    "\n",
    "        # Load the raw data\n",
    "        raw = pd.read_csv(file_path)\n",
    "        train_raw, test_raw = train_test_split(raw, test_size=test_size)\n",
    "\n",
    "        super().__init__(\"custom\", raw, train_raw, test_raw,\n",
    "                         scaling_method, encoding_method)\n",
    "\n",
    "    @property\n",
    "    def categorical(self) -> List[str]:\n",
    "        return self._categorical\n",
    "\n",
    "    @property\n",
    "    def continuous(self) -> List[str]:\n",
    "        return self._continuous\n",
    "\n",
    "    @property\n",
    "    def immutables(self) -> List[str]:\n",
    "        return self._immutables\n",
    "\n",
    "    @property\n",
    "    def target(self) -> str:\n",
    "        return self._target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c73de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicMLModelCatalog(MLModelCatalog):\n",
    "    \"\"\"\n",
    "    Wrapper class for the MLModelCatalog that introduces additional functions\n",
    "    allowing for the efficient and unbiased measurement of the dynamics of recourse.\n",
    "    \n",
    "    Attributes:\n",
    "        data (DataCatalog):\n",
    "            Dataset which will be used to train a model and conduct experiments.\n",
    "        model_type (str):\n",
    "            Black-box model used for classification, currently this class supports only ANNs and Logistic Regression.\n",
    "        backend (str):\n",
    "            Specifies the framework used on the backend, currently this class supports only PyTorch.\n",
    "        cache (Boolean):\n",
    "            If True, the framework will attempt to load a model that was previously cached.\n",
    "        models_home (str):\n",
    "            Path to the directory where models should be saved after they are trained.\n",
    "        load_online: (Boolean):\n",
    "            If True, a pretrained model will be loaded.\n",
    "        kwargs (dict):\n",
    "            Dictionary of optional keyworded arguments.\n",
    "    \"\"\"\n",
    "    def __init__(self, data: DataCatalog, model_type: str, backend: str = \"pytorch\",\n",
    "        cache: bool = True, models_home: str = None, load_online: bool = True, **kwargs) -> None:\n",
    "        \n",
    "        if backend != 'pytorch':\n",
    "            raise NotImplementedError(f\"Only PyTorch models are currently supported\")\n",
    "            \n",
    "        if model_type not in ['ann', 'linear']:\n",
    "            raise NotImplementedError(f\"Model type not supported: {self.model_type}\")\n",
    "            \n",
    "        save_name = model_type\n",
    "        if model_type == \"ann\":\n",
    "            save_name += f\"_layers_{kwargs['save_name_params']}\"\n",
    "            \n",
    "        self._save_name = save_name\n",
    "        \n",
    "        super().__init__(data, model_type, backend, cache,\n",
    "                         models_home, load_online, **kwargs)\n",
    "    \n",
    "    @property\n",
    "    def save_name(self) -> str:\n",
    "        return self._save_name\n",
    "        \n",
    "    def params(self):        \n",
    "        # Attempt to load the saved model\n",
    "        self._model = loading_utils.load_trained_model(save_name=self._save_name,\n",
    "                                                       data_name=self.data.name,\n",
    "                                                       backend=self.backend)\n",
    "        \n",
    "        # This method should only be used when a model is already available\n",
    "        if self._model is None:\n",
    "            raise ValueError(f\"No trained model found for {self._save_name}\")\n",
    "            \n",
    "        for param in self._model.parameters():\n",
    "            print(param)\n",
    "        \n",
    "    def retrain(self, learning_rate=0.01, epochs=5, batch_size=1, hidden_size=[4]):\n",
    "        \"\"\"\n",
    "        Loads a cached model and retrains it on an updated dataset.\n",
    "        \n",
    "        Args:\n",
    "            learning_rate (float):\n",
    "                Size of the step at each epoch of the model training.\n",
    "            epochs (int):\n",
    "                Number of iterations of training.\n",
    "            batch_size (int):\n",
    "                Number of samples used at once in a gradient descent step, if '1' the procedure is stochastic.    \n",
    "        \"\"\"\n",
    "\n",
    "        # Attempt to load the saved model\n",
    "        self._model = loading_utils.load_trained_model(save_name=self._save_name,\n",
    "                                                       data_name=self.data.name,\n",
    "                                                       backend=self.backend)\n",
    "        \n",
    "        # This method should only be used when a model is already available\n",
    "        if self._model is None:\n",
    "            raise ValueError(f\"No trained model found for {self._save_name}\")\n",
    "        \n",
    "        # Sanity check to see if loaded model accuracy makes sense\n",
    "        if self._model is not None:\n",
    "            self._test_accuracy()\n",
    "            \n",
    "        # Get preprocessed data\n",
    "        df_train = self.data.df_train\n",
    "        df_test = self.data.df_test\n",
    "\n",
    "        # All dataframes may have possibly changed\n",
    "        x_train = df_train[list(set(df_train.columns) - {self.data.target})]\n",
    "        y_train = df_train[self.data.target]\n",
    "        x_test = df_test[list(set(df_test.columns) - {self.data.target})]\n",
    "        y_test = df_test[self.data.target]\n",
    "\n",
    "        # Order data (column-wise) before training\n",
    "        x_train = self.get_ordered_features(x_train)\n",
    "        x_test = self.get_ordered_features(x_test)\n",
    "        \n",
    "        log.info(f\"Current balance: train set {y_train.mean()}, test set {y_test.mean()}\")\n",
    "        \n",
    "        # Access the data in a format expected by PyTorch\n",
    "        train_dataset = training_utils.DataFrameDataset(x_train, y_train)\n",
    "        train_loader = training_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = training_utils.DataFrameDataset(x_test, y_test)\n",
    "        test_loader = training_utils.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Retrain the model\n",
    "        training_utils._training_torch(self._model, train_loader, test_loader,\n",
    "                                       learning_rate, epochs)\n",
    "\n",
    "        loading_utils.save_model(model=self._model, save_name=self._save_name,\n",
    "                                 data_name=self.data.name, backend=self.backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0674bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE3000",
   "language": "python",
   "name": "cse3000"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
