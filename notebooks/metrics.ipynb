{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD(x, y, scale=0.5):\n",
    "    \"\"\"\n",
    "    Calculates the Maximum Mean Discrepancy (MMD) between sets of samples from two probability distribution.\n",
    "    MMD = ||µp - µq||^{2}_{H} where µp, µq are mean embeddings in H, a Reproducing Kernel Hilbert Space.\n",
    "    This can be used either per class (which may be more suitable to assess shifts) or on the whole dataset.\n",
    "    \n",
    "    Args:\n",
    "        x (numpy.ndarray):\n",
    "            An n-dimensional sample of length `l` from the first distribution.\n",
    "        y (numpy.ndarray):\n",
    "            An n-dimensional sample of length `l` from the second distribution.\n",
    "        scale (float):\n",
    "            Length-scale of the kernel, influences the smoothness of the transformation.\n",
    "            \n",
    "    Returns:\n",
    "        float: Measure of distance between two distributions (0 means distributions are the same).\n",
    "    \"\"\"\n",
    "    \n",
    "    # RBF is the Gaussian kernel allowing to embed the distribution in RKHS\n",
    "    # As e^x = 1 + x + (1 / 2!) * x^2 ... we can capture all moments of the distribution\n",
    "    k = RBF(length_scale = scale)\n",
    "    \n",
    "    # Implementation of Equation (3) from https://arxiv.org/pdf/1810.11953.pdf\n",
    "    m, n = len(x), len(y)\n",
    "    \n",
    "    # We apply the kernel trick to get an unbiased empirical estimate of the squared population MMD\n",
    "    Kxx = 1 / (m ** 2 - m) * (np.sum(k(x, x)) - np.trace(k(x, x)))\n",
    "    Kxy = 2 / (m * n) * np.sum(k(x, y))\n",
    "    Kyy = 1 / (n ** 2 - n) * (np.sum(k(y, y)) - np.trace(k(y, y)))\n",
    "    \n",
    "    return np.sqrt(np.abs(Kxx + Kyy - Kxy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a91019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_null_hypothesis(x, y, iterations=10000):\n",
    "    \"\"\"\n",
    "    Calculates the MMD for a set of permutations of samples from the two distributions\n",
    "    to measure whether the shift should be considered significant. This works under the assumption\n",
    "    that if samples `x` and `y` come from the same distribution (under the null hypothesis),\n",
    "    then the MMD of permutations of these samples should be similar to MMD(x, y).\n",
    "    \n",
    "    Args:\n",
    "        x (numpy.ndarray):\n",
    "            An n-dimensional sample of length `l` from the first distribution.\n",
    "        y (numpy.ndarray):\n",
    "            An n-dimensional sample of length `l` from the second distribution.\n",
    "        iterations (int):\n",
    "            Number of permutations that should be created for the testing.\n",
    "            \n",
    "    Returns:\n",
    "        numpy.ndarray: Array containing MMDs of all permutations of `x` and `y`.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(x)\n",
    "    mmd_null = np.zeros(iterations)\n",
    "    for index in range(iterations):\n",
    "        permutation = np.random.permutation(np.r_[x, y])\n",
    "        mmd_null[index] = MMD(permutation[:n], permutation[n:])\n",
    "    \n",
    "    return mmd_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fa4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_MMD(data, positive_class, initial_pos):\n",
    "    \"\"\"\n",
    "    Measure the MMD between the initial distribution and the current distribution for both classes.\n",
    "    \n",
    "    Args:\n",
    "        data (pandas.DataFrame):\n",
    "            Records along with their labels.\n",
    "        positive_class (int):\n",
    "            Encoding of the positive class in the dataset.\n",
    "        initial_pos (numpy.ndarray):\n",
    "            A sample of points of the positive class from the initial distribution.\n",
    "            \n",
    "    Returns:\n",
    "        dict: A dictionary containing current values of MMD for the positive and the negative class.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find individuals of both classes\n",
    "    pos_individuals = data.loc[data['target'] == positive_class]\n",
    "    \n",
    "    # Sample individuals of the positive class, distribution of the negative class does not change over time\n",
    "    # TODO this will fail if 100 individuals are not left\n",
    "    updated_pos = pos_individuals.sample(n=min(len(pos_individuals), 100)).to_numpy()\n",
    "    mmd_pos = MMD(initial_pos, updated_pos)\n",
    "    \n",
    "    iterations = 1000\n",
    "    mmd_null = MMD_null_hypothesis(initial_pos, updated_pos, iterations)\n",
    "\n",
    "    p_pos = max(1 / iterations, np.count_nonzero(mmd_null >= mmd_pos) / iterations)\n",
    "    \n",
    "    return {\n",
    "        'value': mmd_pos,\n",
    "        'p': p_pos\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement_distance(data, target, initial_model, updated_model):\n",
    "    \"\"\"\n",
    "    Calculates the Disagreement pseudo-distance defined in https://doi.org/10.1145/1273496.1273541\n",
    "    as Pr(h(x) != h'(x)), that is the probability that labels assigned by one classifier do not agree\n",
    "    with the labels assigned by another classifier. Simply put, it measures the overlap between models.\n",
    "    As this is an empirical measure, we can vary the number of records in `data`.\n",
    "    \n",
    "    Args:\n",
    "        data (pandas.DataFrame):\n",
    "            A withheld set of records that should be predicted by the models (test set).\n",
    "        target (str):\n",
    "            The target column in the dataset.\n",
    "        initial_model (MLModelCatalog):\n",
    "            A model which was trained before recourse has been applied.\n",
    "        updated_model (MLModelCatalog):\n",
    "            A model retrained on a dataset with induced recourse.\n",
    "            \n",
    "    Returns:\n",
    "        float: Probability that the two classifiers disagree on the label of a sample.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check how the initial model would assign labels to the test set\n",
    "    initial_pred = np.argmax(initial_model.predict_proba(data.loc[:, data.columns != target]), axis=1)\n",
    "    \n",
    "    # Check how the updated model would assign labels to the test set\n",
    "    updated_pred = np.argmax(updated_model.predict_proba(data.loc[:, data.columns != target]), axis=1)\n",
    "    \n",
    "    \n",
    "    count_overlap = 0\n",
    "    for index, prediction in enumerate(initial_pred):\n",
    "        if updated_pred[index] == prediction:\n",
    "            count_overlap += 1\n",
    "    \n",
    "    # Find the disagreement pseudo-distance\n",
    "    return (len(initial_pred) - count_overlap) / len(initial_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(dataset, model):\n",
    "    \"\"\"\n",
    "    Computes a set of performance metrics for a classifier.\n",
    "    \n",
    "    Args:\n",
    "        dataset (DataCatalog): \n",
    "            Catalog containing a dataframe, set of train and test records, and the target.\n",
    "        model (MLModelCatalog) \n",
    "            Classifier with additional utilities required by CARLA.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary of statistical measurements of the model performance.\n",
    "    \"\"\"\n",
    "    predictions = model.predict_proba(dataset.df_test.loc[:, dataset.df_test.columns != dataset.target])\n",
    "    predicted_labels = np.argmax(predictions, axis=1) \n",
    "    ground_truth = dataset.df_test.loc[:, dataset.df_test.columns == dataset.target].values.astype(int).flatten() \n",
    "    \n",
    "    return {\n",
    "        \"acc\": accuracy_score(ground_truth, predicted_labels),\n",
    "        \"f1\": f1_score(ground_truth, predicted_labels)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, min_clusters=1, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Applies the k-means algorithm and automatically estimates the elbow point.\n",
    "    The algorithm used to calculate the elbow point is described in 10.1109/ICDCSW.2011.20\n",
    "    \n",
    "    Args:\n",
    "        data (pandas.DataFrame): \n",
    "            Records along with their labels.\n",
    "        min_clusters (int): \n",
    "            Minimal number of clusters that is expected in the dataset.\n",
    "        max_clusters (int):\n",
    "            Maximal number of clusters that is expected in the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        int: Estimated number of clusters that yields the elbow point on an inertia graph.\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    scores = []\n",
    "    # Fit different potential numbers of clusters\n",
    "    for k in range(min_clusters, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42).fit(data)\n",
    "        clusters.append(k)\n",
    "        scores.append(kmeans.inertia_)   \n",
    "    \n",
    "    # Automatically find the elbow point, this should change at some point during the application of AR\n",
    "    # if the counterfactual instances form their own cluster(s), the value returned by this method should change.\n",
    "    kneedle = KneeLocator(clusters, scores, curve=\"convex\", direction=\"decreasing\")\n",
    "\n",
    "    return int(kneedle.elbow)\n",
    "\n",
    "def class_statistics(dataset, aggregate):\n",
    "    \"\"\"\n",
    "    Applies an aggregation function for the two classes described in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (DataCatalog):\n",
    "            Catalog containing a dataframe, set of train and test records, and the target.\n",
    "        aggregate (Callable): \n",
    "            An aggregation function which can be applied on data.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Values return by the aggregation function applied on the positive and negative class.\n",
    "    \"\"\"\n",
    "    features = dataset._df.loc[:, dataset._df.columns != dataset._target]\n",
    "    positive_samples = features.loc[dataset._df[dataset._target] == dataset._positive]\n",
    "    negative_samples = features.loc[dataset._df[dataset._target] == dataset._negative]\n",
    "    return {\"positive\": aggregate(positive_samples).to_dict(), \n",
    "            \"negative\": aggregate(negative_samples).to_dict()}\n",
    "\n",
    "def measure_distribution(dataset):\n",
    "    \"\"\"\n",
    "    Computes a set of statistical measures for the distribution of a dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (DataCatalog):\n",
    "            Catalog containing a dataframe, set of train and test records, and the target.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Statistics calculated for a specific distribution of data.\n",
    "    \"\"\"\n",
    "    num_clusters = k_means(dataset.df.loc[:, dataset.df.columns != dataset.target].to_numpy())\n",
    "    means = class_statistics(dataset, np.mean)\n",
    "    stds = class_statistics(dataset, np.std)\n",
    "    \n",
    "    return {\"num_clusters\": num_clusters, \"means\": means, \"stds\": stds}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE3000",
   "language": "python",
   "name": "cse3000"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
